{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/source/main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "\n",
    "from data_for_train import dataset as my_dataset\n",
    "from model_def.seq2seq_attn import Seq2SeqAttn\n",
    "from utils import pytorch_utils\n",
    "from train.trainer import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input2_text(first_input, *params):\n",
    "    return my_dataset.voc_src.idx2docs(first_input)\n",
    "\n",
    "\n",
    "def target2_text(first_input, *params):\n",
    "    return my_dataset.voc_tgt.idx2docs(first_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Indexing vocabs successfully. Total vocabs: 25390\n",
      "INFO:root:Indexing vocabs successfully. Total vocabs: 50437\n",
      "INFO:root:Vocab for source from file /source/main/vocab/output/src.pkl contains 25390 tokens\n",
      "INFO:root:Vocab for source from file /source/main/vocab/output/tgt.pkl contains 50437 tokens\n",
      "INFO:root:Data at /source/main/data_for_train/output/my_train.csv contains 500 samples\n",
      "INFO:root:Data at /source/main/data_for_train/output/my_eval.csv contains 500 samples\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 500\n",
    "NUM_WORKERS = 0\n",
    "PRINT_EVERY = 100\n",
    "PREDICT_EVERY = 10\n",
    "EVAL_EVERY = 1000\n",
    "PRE_TRAINED_MODEL = ''\n",
    "my_dataset.bootstrap()\n",
    "train_loader = my_dataset.get_dl_train(batch_size=BATCH_SIZE, size=500)\n",
    "eval_loader = my_dataset.get_dl_eval(batch_size=BATCH_SIZE, size=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model architecture: \n",
      "Seq2SeqAttn(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(25390, 256)\n",
      "    (lstm): LSTM(256, 512, num_layers=3, dropout=0.3, bidirectional=True)\n",
      "    (dropout): Dropout(p=0.3)\n",
      "  )\n",
      "  (flatten_hidden_lstm): FlattenHiddenLSTM()\n",
      "  (core_decoder): AttnRawDecoder(\n",
      "    (embedding): Embedding(50437, 256)\n",
      "    (lstm): LSTM(256, 512, num_layers=3, dropout=0.3)\n",
      "    (attention): Attention(\n",
      "      (scoring): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (output_mapping): Linear(in_features=1536, out_features=50437, bias=True)\n",
      "    (dropout): Dropout(p=0.3)\n",
      "  )\n",
      "  (greedy_infer): DecoderGreedyInfer(\n",
      "    (core_decoder): AttnRawDecoder(\n",
      "      (embedding): Embedding(50437, 256)\n",
      "      (lstm): LSTM(256, 512, num_layers=3, dropout=0.3)\n",
      "      (attention): Attention(\n",
      "        (scoring): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (softmax): Softmax()\n",
      "      )\n",
      "      (output_mapping): Linear(in_features=1536, out_features=50437, bias=True)\n",
      "      (dropout): Dropout(p=0.3)\n",
      "    )\n",
      "  )\n",
      "  (xent): CrossEntropyLoss()\n",
      ")\n",
      "INFO:root:Total trainable parameters: 118991365\n"
     ]
    }
   ],
   "source": [
    "model = Seq2SeqAttn(src_vocab_size=len(my_dataset.voc_src.index2word),\n",
    "                tgt_vocab_size=len(my_dataset.voc_tgt.index2word),\n",
    "                start_idx=2,\n",
    "                end_idx=3\n",
    "                )\n",
    "model.train()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "model.to(device)\n",
    "logging.info('Model architecture: \\n%s', model)\n",
    "logging.info('Total trainable parameters: %s', pytorch_utils.count_parameters(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Param: encoder.embedding.weight contributes 6499840 weights\n",
      "Param: encoder.lstm.weight_ih_l0 contributes 524288 weights\n",
      "Param: encoder.lstm.weight_hh_l0 contributes 1048576 weights\n",
      "Param: encoder.lstm.bias_ih_l0 contributes 2048 weights\n",
      "Param: encoder.lstm.bias_hh_l0 contributes 2048 weights\n",
      "Param: encoder.lstm.weight_ih_l0_reverse contributes 524288 weights\n",
      "Param: encoder.lstm.weight_hh_l0_reverse contributes 1048576 weights\n",
      "Param: encoder.lstm.bias_ih_l0_reverse contributes 2048 weights\n",
      "Param: encoder.lstm.bias_hh_l0_reverse contributes 2048 weights\n",
      "Param: encoder.lstm.weight_ih_l1 contributes 2097152 weights\n",
      "Param: encoder.lstm.weight_hh_l1 contributes 1048576 weights\n",
      "Param: encoder.lstm.bias_ih_l1 contributes 2048 weights\n",
      "Param: encoder.lstm.bias_hh_l1 contributes 2048 weights\n",
      "Param: encoder.lstm.weight_ih_l1_reverse contributes 2097152 weights\n",
      "Param: encoder.lstm.weight_hh_l1_reverse contributes 1048576 weights\n",
      "Param: encoder.lstm.bias_ih_l1_reverse contributes 2048 weights\n",
      "Param: encoder.lstm.bias_hh_l1_reverse contributes 2048 weights\n",
      "Param: encoder.lstm.weight_ih_l2 contributes 2097152 weights\n",
      "Param: encoder.lstm.weight_hh_l2 contributes 1048576 weights\n",
      "Param: encoder.lstm.bias_ih_l2 contributes 2048 weights\n",
      "Param: encoder.lstm.bias_hh_l2 contributes 2048 weights\n",
      "Param: encoder.lstm.weight_ih_l2_reverse contributes 2097152 weights\n",
      "Param: encoder.lstm.weight_hh_l2_reverse contributes 1048576 weights\n",
      "Param: encoder.lstm.bias_ih_l2_reverse contributes 2048 weights\n",
      "Param: encoder.lstm.bias_hh_l2_reverse contributes 2048 weights\n",
      "Param: core_decoder.embedding.weight contributes 12911872 weights\n",
      "Param: core_decoder.lstm.weight_ih_l0 contributes 524288 weights\n",
      "Param: core_decoder.lstm.weight_hh_l0 contributes 1048576 weights\n",
      "Param: core_decoder.lstm.bias_ih_l0 contributes 2048 weights\n",
      "Param: core_decoder.lstm.bias_hh_l0 contributes 2048 weights\n",
      "Param: core_decoder.lstm.weight_ih_l1 contributes 1048576 weights\n",
      "Param: core_decoder.lstm.weight_hh_l1 contributes 1048576 weights\n",
      "Param: core_decoder.lstm.bias_ih_l1 contributes 2048 weights\n",
      "Param: core_decoder.lstm.bias_hh_l1 contributes 2048 weights\n",
      "Param: core_decoder.lstm.weight_ih_l2 contributes 1048576 weights\n",
      "Param: core_decoder.lstm.weight_hh_l2 contributes 1048576 weights\n",
      "Param: core_decoder.lstm.bias_ih_l2 contributes 2048 weights\n",
      "Param: core_decoder.lstm.bias_hh_l2 contributes 2048 weights\n",
      "Param: core_decoder.attention.scoring.weight contributes 524288 weights\n",
      "Param: core_decoder.attention.scoring.bias contributes 1024 weights\n",
      "Param: core_decoder.output_mapping.weight contributes 77471232 weights\n",
      "Param: core_decoder.output_mapping.bias contributes 50437 weights\n",
      "Total: 118991365\n"
     ]
    }
   ],
   "source": [
    "pytorch_utils.show_detail_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Path /source/main/train/output/saved_models//Seq2SeqAttn/2019-05-29T16:44:23 does not exist, auto created !\n",
      "INFO:root:----------------------- START TRAINING -----------------------\n",
      "INFO:root:Step: 1 \t L_mean: 10.8315Â±0.0000 \t w_a: 0.0337 \t s_a: 0.0000 \t Duration: 1.4438 s/step\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 296.00 MiB (GPU 0; 7.93 GiB total capacity; 1.84 GiB already allocated; 281.19 MiB free; 277.92 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-210ab0320e69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m train(model, train_loader, eval_loader, dir_checkpoint='/source/main/train/output/saved_models/', device=device,\n\u001b[1;32m     11\u001b[0m       \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRINT_EVERY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPREDICT_EVERY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEVAL_EVERY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       input_transform=input2_text, output_transform=target2_text, init_step=init_step)\n\u001b[0m",
      "\u001b[0;32m/source/main/train/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, eval_loader, dir_checkpoint, device, num_epoch, print_every, predict_every, eval_every, input_transform, output_transform, init_step)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mt_loss_tracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/source/main/model_def/seq2seq_attn.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, word_input, target, length)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 296.00 MiB (GPU 0; 7.93 GiB total capacity; 1.84 GiB already allocated; 281.19 MiB free; 277.92 MiB cached)"
     ]
    }
   ],
   "source": [
    "init_step = 0\n",
    "# Restore model\n",
    "if PRE_TRAINED_MODEL != '':\n",
    "    checkpoint = torch.load(PRE_TRAINED_MODEL, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    init_step = checkpoint.get('step', 0)\n",
    "    logging.info('Load pre-trained model from %s successfully', PRE_TRAINED_MODEL)\n",
    "\n",
    "train(model, train_loader, eval_loader, dir_checkpoint='/source/main/train/output/saved_models/', device=device,\n",
    "      num_epoch=NUM_EPOCHS, print_every=PRINT_EVERY, predict_every=PREDICT_EVERY, eval_every=EVAL_EVERY,\n",
    "      input_transform=input2_text, output_transform=target2_text, init_step=init_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
